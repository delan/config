From 755f6e817788ac8c6a4b11a15e323eb21f4ea19a Mon Sep 17 00:00:00 2001
From: Rob N <rob.norris@klarasystems.com>
Date: Sat, 20 Apr 2024 09:41:31 +1000
Subject: [PATCH] vdev_disk: page iterator and BIO fill debugging options

Set zfs_vdev_disk_debug_bio_fill=1. If the kernel rejects an IO, OpenZFS
will log some stuff describing how the IO was constructed, which
hopefully will help us understand what happened.

Set zfs_abd_page_iter_disable_compound=1. This will stop the page
iterator from trying to do more efficient handling of compound pages,
which may or may not be implicated.

Includes backport of

        fa2480f5b abd_iter_page: rework to handle multipage scatterlist

Signed-off-by: Rob Norris <rob.norris@klarasystems.com>
---
 include/sys/abd.h               |   4 +-
 module/os/linux/zfs/abd_os.c    | 140 +++++++++++++++++++++-----------
 module/os/linux/zfs/vdev_disk.c | 116 +++++++++++++++++++++++++-
 module/zfs/abd.c                |   5 +-
 4 files changed, 211 insertions(+), 54 deletions(-)

diff --git a/include/sys/abd.h b/include/sys/abd.h
index bee38b831bc0..ffc455c02bd4 100644
--- a/include/sys/abd.h
+++ b/include/sys/abd.h
@@ -46,6 +46,7 @@ typedef enum abd_flags {
 	ABD_FLAG_GANG_FREE	= 1 << 7, /* gang ABD is responsible for mem */
 	ABD_FLAG_ZEROS		= 1 << 8, /* ABD for zero-filled buffer */
 	ABD_FLAG_ALLOCD		= 1 << 9, /* we allocated the abd_t */
+	ABD_FLAG_COMPOUND_PAGE	= 1 << 10, /* page iter adjusted for compound */
 } abd_flags_t;
 
 typedef struct abd {
@@ -80,7 +81,8 @@ typedef struct abd {
 typedef int abd_iter_func_t(void *buf, size_t len, void *priv);
 typedef int abd_iter_func2_t(void *bufa, void *bufb, size_t len, void *priv);
 #if defined(__linux__) && defined(_KERNEL)
-typedef int abd_iter_page_func_t(struct page *, size_t, size_t, void *);
+typedef int abd_iter_page_func_t(struct page *, size_t, size_t, abd_flags_t,
+    void *);
 #endif
 
 extern int zfs_abd_scatter_enabled;
diff --git a/module/os/linux/zfs/abd_os.c b/module/os/linux/zfs/abd_os.c
index d3255dcbc0f7..67d1fa0b86bd 100644
--- a/module/os/linux/zfs/abd_os.c
+++ b/module/os/linux/zfs/abd_os.c
@@ -1015,13 +1015,63 @@ abd_cache_reap_now(void)
 }
 
 #if defined(_KERNEL)
+
 /*
- * Yield the next page struct and data offset and size within it, without
+ * This is abd_iter_page(), the function underneath abd_iterate_page_func().
+ * It yields the next page struct and data offset and size within it, without
  * mapping it into the address space.
  */
+
+/*
+ * "Compound pages" are a group of pages that can be referenced from a single
+ * struct page *. Its organised as a "head" page, followed by a series of
+ * "tail" pages.
+ *
+ * In OpenZFS, compound pages are allocated using the __GFP_COMP flag, which we
+ * get from scatter ABDs and SPL vmalloc slabs (ie >16K allocations). So a
+ * great many of the IO buffers we get are going to be of this type.
+ *
+ * The tail pages are just regular PAGESIZE pages, and can be safely used
+ * as-is. However, the head page has length covering itself and all the tail
+ * pages. If the ABD chunk spans multiple pages, then we can use the head page
+ * and a >PAGESIZE length, which is far more efficient.
+ *
+ * Before kernel 4.5 however, compound page heads were refcounted separately
+ * from tail pages, such that moving back to the head page would require us to
+ * take a reference to it and releasing it once we're completely finished with
+ * it. In practice, that means when our caller is done with the ABD, which we
+ * have no insight into from here. Rather than contort this API to track head
+ * page references on such ancient kernels, we disable this special compound
+ * page handling on 4.5, instead just using treating each page within it as a
+ * regular PAGESIZE page (which it is). This is slightly less efficient, but
+ * makes everything far simpler.
+ *
+ * The below test sets/clears ABD_ITER_COMPOUND_PAGES to enable/disable the
+ * special handling, and also defines the ABD_ITER_PAGE_SIZE(page) macro to
+ * understand compound pages, or not, as required.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 5, 0)
+#define	ABD_ITER_COMPOUND_PAGES		1
+#define	ABD_ITER_PAGE_SIZE(page)	\
+	(PageCompound(page) ? page_size(page) : PAGESIZE)
+#else
+#undef ABD_ITER_COMPOUND_PAGES
+#define	ABD_ITER_PAGE_SIZE(page)	(PAGESIZE)
+#endif
+
+#ifdef ABD_ITER_COMPOUND_PAGES
+/*
+ * Eye of suspicion is upon compound page handling, so lets have a runtime way
+ * to turn it off too.
+ */
+static unsigned zfs_abd_page_iter_disable_compound = 0;
+#endif
+
 void
 abd_iter_page(struct abd_iter *aiter)
 {
+	aiter->iter_abd->abd_flags &= ~ABD_FLAG_COMPOUND_PAGE;
+
 	if (abd_iter_at_end(aiter)) {
 		aiter->iter_page = NULL;
 		aiter->iter_page_doff = 0;
@@ -1032,6 +1082,12 @@ abd_iter_page(struct abd_iter *aiter)
 	struct page *page;
 	size_t doff, dsize;
 
+	/*
+	 * Find the page, and the start of the data within it. This is computed
+	 * differently for linear and scatter ABDs; linear is referenced by
+	 * virtual memory location, while scatter is referenced by page
+	 * pointer.
+	 */
 	if (abd_is_linear(aiter->iter_abd)) {
 		ASSERT3U(aiter->iter_pos, ==, aiter->iter_offset);
 
@@ -1044,70 +1100,54 @@ abd_iter_page(struct abd_iter *aiter)
 
 		/* offset of address within the page */
 		doff = offset_in_page(paddr);
-
-		/* total data remaining in abd from this position */
-		dsize = aiter->iter_abd->abd_size - aiter->iter_offset;
 	} else {
 		ASSERT(!abd_is_gang(aiter->iter_abd));
 
 		/* current scatter page */
-		page = sg_page(aiter->iter_sg);
+		page = nth_page(sg_page(aiter->iter_sg),
+		    aiter->iter_offset >> PAGE_SHIFT);
 
 		/* position within page */
-		doff = aiter->iter_offset;
-
-		/* remaining data in scatterlist */
-		dsize = MIN(aiter->iter_sg->length - aiter->iter_offset,
-		    aiter->iter_abd->abd_size - aiter->iter_pos);
+		doff = aiter->iter_offset & (PAGESIZE - 1);
 	}
-	ASSERT(page);
 
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 5, 0)
-	if (PageTail(page)) {
+#ifdef ABD_ITER_COMPOUND_PAGES
+	if (PageTail(page) && !zfs_abd_page_iter_disable_compound) {
 		/*
-		 * This page is part of a "compound page", which is a group of
-		 * pages that can be referenced from a single struct page *.
-		 * Its organised as a "head" page, followed by a series of
-		 * "tail" pages.
-		 *
-		 * In OpenZFS, compound pages are allocated using the
-		 * __GFP_COMP flag, which we get from scatter ABDs and SPL
-		 * vmalloc slabs (ie >16K allocations). So a great many of the
-		 * IO buffers we get are going to be of this type.
-		 *
-		 * The tail pages are just regular PAGE_SIZE pages, and can be
-		 * safely used as-is. However, the head page has length
-		 * covering itself and all the tail pages. If this ABD chunk
-		 * spans multiple pages, then we can use the head page and a
-		 * >PAGE_SIZE length, which is far more efficient.
-		 *
-		 * To do this, we need to adjust the offset to be counted from
-		 * the head page. struct page for compound pages are stored
-		 * contiguously, so we can just adjust by a simple offset.
-		 *
-		 * Before kernel 4.5, compound page heads were refcounted
-		 * separately, such that moving back to the head page would
-		 * require us to take a reference to it and releasing it once
-		 * we're completely finished with it. In practice, that means
-		 * when our caller is done with the ABD, which we have no
-		 * insight into from here. Rather than contort this API to
-		 * track head page references on such ancient kernels, we just
-		 * compile this block out and use the tail pages directly. This
-		 * is slightly less efficient, but makes everything far
-		 * simpler.
+		 * If this is a compound tail page, move back to the head, and
+		 * adjust the offset to match. This may let us yield a much
+		 * larger amount of data from a single logical page, and so
+		 * leave our caller with fewer pages to process.
 		 */
 		struct page *head = compound_head(page);
 		doff += ((page - head) * PAGESIZE);
 		page = head;
+
+		aiter->iter_abd->abd_flags |= ABD_FLAG_COMPOUND_PAGE;
 	}
 #endif
 
-	/* final page and position within it */
+	ASSERT(page);
+
+	/*
+	 * Compute the maximum amount of data we can take from this page. This
+	 * is the smaller of:
+	 * - the remaining space in the page
+	 * - the remaining space in this scatterlist entry (which may not cover
+	 *   the entire page)
+	 * - the remaining space in the abd (which may not cover the entire
+	 *   scatterlist entry)
+	 */
+	dsize = MIN(ABD_ITER_PAGE_SIZE(page) - doff,
+	    aiter->iter_abd->abd_size - aiter->iter_pos);
+	if (!abd_is_linear(aiter->iter_abd))
+		dsize = MIN(dsize, aiter->iter_sg->length - aiter->iter_offset);
+	ASSERT3U(dsize, >, 0);
+
+	/* final iterator outputs */
 	aiter->iter_page = page;
 	aiter->iter_page_doff = doff;
-
-	/* amount of data in the chunk, up to the end of the page */
-	aiter->iter_page_dsize = MIN(dsize, page_size(page) - doff);
+	aiter->iter_page_dsize = dsize;
 }
 
 /*
@@ -1270,4 +1310,10 @@ module_param(zfs_abd_scatter_max_order, uint, 0644);
 MODULE_PARM_DESC(zfs_abd_scatter_max_order,
 	"Maximum order allocation used for a scatter ABD.");
 
+#ifdef ABD_ITER_COMPOUND_PAGES
+module_param(zfs_abd_page_iter_disable_compound, uint, 0644);
+MODULE_PARM_DESC(zfs_abd_page_iter_disable_compound,
+	"Set to 1 to disable special handling of compound pages.");
+#endif
+
 #endif /* _KERNEL */
diff --git a/module/os/linux/zfs/vdev_disk.c b/module/os/linux/zfs/vdev_disk.c
index 943e534ef5b0..06b5dd85a583 100644
--- a/module/os/linux/zfs/vdev_disk.c
+++ b/module/os/linux/zfs/vdev_disk.c
@@ -84,6 +84,15 @@ typedef struct vdev_disk {
  */
 uint_t zfs_vdev_disk_max_segs = 0;
 
+/*
+ * BIO fill debugging. 0 disables it (default). If enabled, the BIO fill layout
+ * is record if as its filled. If set to 1, layout is logged to the kernel log
+ * on error. If 2, layout is logged for all IOs.
+ */
+uint_t zfs_vdev_disk_debug_bio_fill = 0;
+
+#define	DEBUG_BIO_FILL_ALLOC_SIZE	(256)
+
 /*
  * Unique identifier for the exclusive vdev holder.
  */
@@ -682,6 +691,11 @@ typedef struct {
 
 	struct bio	*vbio_bio;	/* pointer to the current bio */
 	int		vbio_flags;	/* bio flags */
+
+	/* debugging info, when zfs_vdev_disk_debug_bio_fill > 0 */
+	char		*vbio_debug;
+	size_t		vbio_debug_size;
+	size_t		vbio_debug_pos;
 } vbio_t;
 
 static vbio_t *
@@ -699,17 +713,86 @@ vbio_alloc(zio_t *zio, struct block_device *bdev, int flags)
 	vbio->vbio_bio = NULL;
 	vbio->vbio_flags = flags;
 
+	if (zfs_vdev_disk_debug_bio_fill > 0) {
+		vbio->vbio_debug =
+		    kmem_alloc(DEBUG_BIO_FILL_ALLOC_SIZE, KM_SLEEP);
+		vbio->vbio_debug_size = DEBUG_BIO_FILL_ALLOC_SIZE;
+		vbio->vbio_debug_pos = 0;
+	}
+
 	return (vbio);
 }
 
+static inline void
+vbio_debug_append(vbio_t *vbio, char c)
+{
+	if (vbio->vbio_debug == NULL)
+		return;
+
+	vbio->vbio_debug[vbio->vbio_debug_pos++] = c;
+
+	if (vbio->vbio_debug_pos < vbio->vbio_debug_size)
+		return;
+
+	size_t new_size = vbio->vbio_debug_size * 2;
+	char *new = kmem_alloc(new_size, KM_SLEEP);
+	memcpy(new, vbio->vbio_debug, vbio->vbio_debug_size);
+	kmem_free(vbio->vbio_debug, vbio->vbio_debug_size);
+	vbio->vbio_debug = new;
+	vbio->vbio_debug_size = new_size;
+}
+
+static inline void
+vbio_debug_append_size(vbio_t *vbio, size_t size)
+{
+	if (vbio->vbio_debug == NULL)
+		return;
+
+	const uint_t segs = size >> 9;
+	const uint_t rem = size & 0x1ff;
+
+	if (segs < 16 && rem == 0) {
+		const char csegs =
+		    (segs < 10) ? (segs + 0x30) : (segs + (0x61-10));
+		vbio_debug_append(vbio, csegs);
+	} else {
+		char buf[16];
+		if (rem == 0)
+			snprintf(buf, sizeof (buf), "/%x/", segs);
+		else
+			snprintf(buf, sizeof (buf), "/%x+%x/", segs, rem);
+		for (char *c = buf; *c; c++)
+			vbio_debug_append(vbio, *c);
+	}
+}
+
+static void
+vbio_debug_log(vbio_t *vbio)
+{
+	printk(KERN_INFO "vbio debug: ms=%x mb=%x bs=%x "
+	    "ty=%u sz=%llx bt=%c %.*s\n",
+	    vbio->vbio_max_segs, vbio->vbio_max_bytes, (~vbio->vbio_lbs_mask)+1,
+	    vbio->vbio_zio->io_type, vbio->vbio_zio->io_size,
+	    abd_is_linear(vbio->vbio_zio->io_abd) ? 'L' :
+	    abd_is_gang(vbio->vbio_zio->io_abd) ? 'G' : 'S',
+	    (int)vbio->vbio_debug_pos, vbio->vbio_debug);
+}
+
 BIO_END_IO_PROTO(vbio_completion, bio, error);
 
 static int
-vbio_add_page(vbio_t *vbio, struct page *page, uint_t size, uint_t offset)
+vbio_add_page(vbio_t *vbio, struct page *page, uint_t size, uint_t offset,
+    abd_flags_t abdflags)
 {
 	struct bio *bio = vbio->vbio_bio;
 	uint_t ssize;
 
+	vbio_debug_append_size(vbio, size);
+	vbio_debug_append(vbio, '[');
+
+	if (abdflags & ABD_FLAG_COMPOUND_PAGE)
+		vbio_debug_append(vbio, 'C');
+
 	while (size > 0) {
 		if (bio == NULL) {
 			/* New BIO, allocate and set up */
@@ -723,10 +806,13 @@ vbio_add_page(vbio_t *vbio, struct page *page, uint_t size, uint_t offset)
 			    WRITE : READ, vbio->vbio_flags);
 
 			if (vbio->vbio_bio) {
+				vbio_debug_append(vbio, '$');
 				bio_chain(vbio->vbio_bio, bio);
 				vdev_submit_bio(vbio->vbio_bio);
 			}
 			vbio->vbio_bio = bio;
+
+			vbio_debug_append(vbio, '^');
 		}
 
 		/*
@@ -741,12 +827,16 @@ vbio_add_page(vbio_t *vbio, struct page *page, uint_t size, uint_t offset)
 		    vbio->vbio_lbs_mask);
 		if (ssize > 0 &&
 		    bio_add_page(bio, page, ssize, offset) == ssize) {
+			vbio_debug_append_size(vbio, ssize);
 			/* Accepted, adjust and load any remaining. */
 			size -= ssize;
 			offset += ssize;
 			continue;
 		}
 
+		vbio_debug_append_size(vbio, ssize);
+		vbio_debug_append(vbio, '!');
+
 		/* No room, set up for a new BIO and loop */
 		vbio->vbio_offset += BIO_BI_SIZE(bio);
 
@@ -754,15 +844,18 @@ vbio_add_page(vbio_t *vbio, struct page *page, uint_t size, uint_t offset)
 		bio = NULL;
 	}
 
+	vbio_debug_append(vbio, ']');
+
 	return (0);
 }
 
 /* Iterator callback to submit ABD pages to the vbio. */
 static int
-vbio_fill_cb(struct page *page, size_t off, size_t len, void *priv)
+vbio_fill_cb(struct page *page, size_t off, size_t len, abd_flags_t abdflags,
+    void *priv)
 {
 	vbio_t *vbio = priv;
-	return (vbio_add_page(vbio, page, len, off));
+	return (vbio_add_page(vbio, page, len, off, abdflags));
 }
 
 /* Create some BIOs, fill them with data and submit them */
@@ -792,6 +885,7 @@ vbio_submit(vbio_t *vbio, abd_t *abd, uint64_t size)
 	 * called and free the vbio before this task is run again, so we must
 	 * consider it invalid from this point.
 	 */
+	vbio_debug_append(vbio, '$');
 	vdev_submit_bio(vbio->vbio_bio);
 
 	blk_finish_plug(&plug);
@@ -823,6 +917,14 @@ BIO_END_IO_PROTO(vbio_completion, bio, error)
 	/* Return the BIO to the kernel */
 	bio_put(bio);
 
+	/* Emit debug output if wanted */
+	if (vbio->vbio_debug != NULL) {
+		if ((zfs_vdev_disk_debug_bio_fill == 1 && zio->io_error != 0) ||
+		    zfs_vdev_disk_debug_bio_fill == 2)
+			vbio_debug_log(vbio);
+		kmem_free(vbio->vbio_debug, vbio->vbio_debug_size);
+	}
+
 	/*
 	 * If we copied the ABD before issuing it, clean up and return the copy
 	 * to the ADB, with changes if appropriate.
@@ -861,8 +963,11 @@ typedef struct {
 } vdev_disk_check_pages_t;
 
 static int
-vdev_disk_check_pages_cb(struct page *page, size_t off, size_t len, void *priv)
+vdev_disk_check_pages_cb(struct page *page, size_t off, size_t len,
+    abd_flags_t abdflags, void *priv)
 {
+	(void) page;
+	(void) abdflags;
 	vdev_disk_check_pages_t *s = priv;
 
 	/*
@@ -1661,3 +1766,6 @@ ZFS_MODULE_PARAM(zfs_vdev_disk, zfs_vdev_disk_, max_segs, UINT, ZMOD_RW,
 ZFS_MODULE_PARAM_CALL(zfs_vdev_disk, zfs_vdev_disk_, classic,
     vdev_disk_param_set_classic, param_get_uint, ZMOD_RD,
 	"Use classic BIO submission method");
+
+ZFS_MODULE_PARAM(zfs_vdev_disk, zfs_vdev_disk_, debug_bio_fill, UINT, ZMOD_RW,
+	"BIO fill debugging: 0 - disable, 1 - errors only, 2 - everything");
diff --git a/module/zfs/abd.c b/module/zfs/abd.c
index 3388e2357305..ecd8a6ced761 100644
--- a/module/zfs/abd.c
+++ b/module/zfs/abd.c
@@ -113,7 +113,8 @@ abd_verify(abd_t *abd)
 	ASSERT3U(abd->abd_flags, ==, abd->abd_flags & (ABD_FLAG_LINEAR |
 	    ABD_FLAG_OWNER | ABD_FLAG_META | ABD_FLAG_MULTI_ZONE |
 	    ABD_FLAG_MULTI_CHUNK | ABD_FLAG_LINEAR_PAGE | ABD_FLAG_GANG |
-	    ABD_FLAG_GANG_FREE | ABD_FLAG_ZEROS | ABD_FLAG_ALLOCD));
+	    ABD_FLAG_GANG_FREE | ABD_FLAG_ZEROS | ABD_FLAG_ALLOCD |
+	    ABD_FLAG_COMPOUND_PAGE));
 	IMPLY(abd->abd_parent != NULL, !(abd->abd_flags & ABD_FLAG_OWNER));
 	IMPLY(abd->abd_flags & ABD_FLAG_META, abd->abd_flags & ABD_FLAG_OWNER);
 	if (abd_is_linear(abd)) {
@@ -851,7 +852,7 @@ abd_iterate_page_func(abd_t *abd, size_t off, size_t size,
 		ASSERT3U(len, >, 0);
 
 		ret = func(aiter.iter_page, aiter.iter_page_doff,
-		    len, private);
+		    len, abd->abd_flags, private);
 
 		aiter.iter_page = NULL;
 		aiter.iter_page_doff = 0;
